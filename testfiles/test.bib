@inproceedings{Huang:2016:MFE:2911996.2912039,
 author = {Huang, Yuchi and Khan, Saad},
 title = {Mirroring Facial Expressions: Evidence from Visual Analysis of Dyadic Interactions},
 booktitle = {Proceedings of the 2016 ACM on International Conference on Multimedia Retrieval},
 series = {ICMR '16},
 year = {2016},
 isbn = {978-1-4503-4359-6},
 location = {New York, New York, USA},
 pages = {225--228},
 numpages = {4},
 url = {http://doi.acm.org/10.1145/2911996.2912039},
 doi = {10.1145/2911996.2912039},
 acmid = {2912039},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {dyadic interactions, facial expression analysis, temporal pyramid matching kernel},
 abstract = {We present results from a pilot study that explored evidence of non-conscious facial expression mirroring exhibited by human dyads in face-to-face interactions. We captured video data of study participants engaged in an online collaborative activity on science topics. The data was sub-sampled {and} organized into two sets: one consisting of time-synchronized video clips from dyad pairs {and} the other from unrelated nominal-dyads (or non-dyads). The videos were analyzed with an automated facial expression approach {and} distance between two video clips of each pair (from both two sets) was computed using a temporal pyramid matching strategy. By employing a two-sample t-test on these two populations, our results demonstrate a statistically significant convergence or mirroring of facial expressions between dyad pairs, which holds over a wide range of model parameter settings {and} extensive experimentation.}
} 


@proceedings{ICMR16,
 title = {Proceedings of the 2016 ACM on International Conference on Multimedia Retrieval},
 editor = {Kender, John and Smith, John R. and Chang, Shih-Fu},
 date = {2016-06-06/2016-06-09}
}